{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9521407d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     19\u001b[39m sns.set_palette(\u001b[33m\"\u001b[39m\u001b[33mhusl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Load the cleaned data\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# In practice, this would come from the previous notebook\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataProcessor\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_engineering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatureEngineer\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Initialize and load data\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Feature Engineering - Customer Churn Prediction\n",
    "# \n",
    "# This notebook focuses on creating new features and preparing the data for modeling.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# %%\n",
    "# Load the cleaned data\n",
    "# In practice, this would come from the previous notebook\n",
    "from src.data_processing import DataProcessor\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "\n",
    "# Initialize and load data\n",
    "processor = DataProcessor()\n",
    "df = processor.load_data()\n",
    "df = processor.clean_data()\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Exploratory Data Analysis for Feature Engineering\n",
    "\n",
    "# %%\n",
    "# Check current features and their types\n",
    "print(\"Current features:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# %%\n",
    "# Analyze numerical features distribution\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    axes[i].hist(df[feature], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Analyze categorical features\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', \n",
    "                       'InternetService', 'Contract', 'PaymentMethod']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    if i < len(axes):\n",
    "        # Calculate churn rates by category\n",
    "        churn_by_category = df.groupby(feature)['Churn'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Plot\n",
    "        bars = axes[i].bar(range(len(churn_by_category)), churn_by_category.values, \n",
    "                          color=['#A23B72', '#2E86AB', '#F18F01', '#C73E1D'][:len(churn_by_category)])\n",
    "        axes[i].set_title(f'Churn Rate by {feature}', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Churn Rate')\n",
    "        axes[i].set_xticks(range(len(churn_by_category)))\n",
    "        axes[i].set_xticklabels(churn_by_category.index, rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, churn_by_category.values):\n",
    "            axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                        f'{value:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Create New Engineered Features\n",
    "\n",
    "# %%\n",
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "# %%\n",
    "# Create new features\n",
    "df_engineered = engineer.create_new_features(df)\n",
    "\n",
    "# Display the new features\n",
    "new_features = ['TenureGroup', 'MonthlySpendCategory', 'AvgChargePerTenure', 'HasMultipleServices']\n",
    "print(\"New features created:\")\n",
    "print(df_engineered[new_features].head())\n",
    "\n",
    "# %%\n",
    "# Analyze the new features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Tenure Group analysis\n",
    "tenure_churn = df_engineered.groupby('TenureGroup')['Churn'].mean()\n",
    "axes[0,0].bar(tenure_churn.index.astype(str), tenure_churn.values, color='#2E86AB')\n",
    "axes[0,0].set_title('Churn Rate by Tenure Group', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(tenure_churn.values):\n",
    "    axes[0,0].text(i, v + 0.01, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Monthly Spend Category analysis\n",
    "spend_churn = df_engineered.groupby('MonthlySpendCategory')['Churn'].mean()\n",
    "axes[0,1].bar(spend_churn.index.astype(str), spend_churn.values, color='#A23B72')\n",
    "axes[0,1].set_title('Churn Rate by Monthly Spend Category', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(spend_churn.values):\n",
    "    axes[0,1].text(i, v + 0.01, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Avg Charge Per Tenure\n",
    "axes[1,0].scatter(df_engineered['AvgChargePerTenure'], df_engineered['Churn'], \n",
    "                 alpha=0.5, color='#F18F01')\n",
    "axes[1,0].set_xlabel('Average Charge Per Tenure Month')\n",
    "axes[1,0].set_ylabel('Churn (0=No, 1=Yes)')\n",
    "axes[1,0].set_title('Churn vs Average Monthly Charge', fontweight='bold')\n",
    "\n",
    "# Has Multiple Services\n",
    "service_churn = df_engineered.groupby('HasMultipleServices')['Churn'].mean()\n",
    "axes[1,1].bar(['No Multiple Services', 'Has Multiple Services'], service_churn.values, color='#C73E1D')\n",
    "axes[1,1].set_title('Churn Rate by Multiple Services', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Churn Rate')\n",
    "for i, v in enumerate(service_churn.values):\n",
    "    axes[1,1].text(i, v + 0.01, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Feature Correlation Analysis\n",
    "\n",
    "# %%\n",
    "# Select numerical features for correlation analysis\n",
    "numerical_features_extended = numerical_features + ['AvgChargePerTenure', 'HasMultipleServices']\n",
    "correlation_matrix = df_engineered[numerical_features_extended + ['Churn']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Prepare Data for Modeling\n",
    "\n",
    "# %%\n",
    "# Prepare the final feature set\n",
    "X = df_engineered.drop('Churn', axis=1)\n",
    "y = df_engineered['Churn']\n",
    "\n",
    "print(\"Feature set shape:\", X.shape)\n",
    "print(\"Target variable distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nChurn rate:\", f\"{y.mean():.2%}\")\n",
    "\n",
    "# %%\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', \n",
    "                       'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                       'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "                       'PaperlessBilling', 'PaymentMethod', 'TenureGroup', \n",
    "                       'MonthlySpendCategory']\n",
    "\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargePerTenure', 'HasMultipleServices']\n",
    "\n",
    "print(\"Categorical features:\", len(categorical_features))\n",
    "print(\"Numerical features:\", len(numerical_features))\n",
    "\n",
    "# %%\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "all_feature_names = numerical_features + list(cat_feature_names)\n",
    "\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"After preprocessing: {X_processed.shape[1]}\")\n",
    "print(f\"Final feature names: {len(all_feature_names)}\")\n",
    "\n",
    "# %%\n",
    "# Display some of the transformed features\n",
    "feature_importance_placeholder = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance_placeholder': np.random.rand(len(all_feature_names))\n",
    "}).sort_values('importance_placeholder', ascending=False)\n",
    "\n",
    "print(\"Top 20 features (placeholder for model importance):\")\n",
    "feature_importance_placeholder.head(20)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Feature Importance Analysis (Preliminary)\n",
    "\n",
    "# %%\n",
    "# Quick Random Forest to see initial feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train a quick Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')\n",
    "plt.title('Top 20 Most Important Features (Random Forest)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Display the top features\n",
    "print(\"Top 10 most important features:\")\n",
    "print(top_features.head(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Save Processed Data\n",
    "\n",
    "# %%\n",
    "# Save the processed data for modeling\n",
    "import joblib\n",
    "\n",
    "# Save processed features\n",
    "processed_data = {\n",
    "    'X_processed': X_processed,\n",
    "    'y': y,\n",
    "    'feature_names': all_feature_names,\n",
    "    'preprocessor': preprocessor\n",
    "}\n",
    "\n",
    "joblib.dump(processed_data, 'data/processed/processed_data.pkl')\n",
    "print(\"Processed data saved successfully!\")\n",
    "\n",
    "# %%\n",
    "# Summary of feature engineering\n",
    "print(\"=== FEATURE ENGINEERING SUMMARY ===\")\n",
    "print(f\"ðŸ“Š Original dataset: {processor.df.shape[1]} features\")\n",
    "print(f\"ðŸ”§ Engineered features: {len(new_features)} new features created\")\n",
    "print(f\"ðŸŽ¯ Final feature set: {X_processed.shape[1]} features after encoding\")\n",
    "print(f\"ðŸ“ˆ Key insights:\")\n",
    "print(f\"   - Tenure Group shows clear churn patterns\")\n",
    "print(f\"   - Monthly Spend Category correlates with churn\")\n",
    "print(f\"   - Customers with multiple services have lower churn\")\n",
    "print(f\"ðŸ’¾ Data saved for modeling phase\")\n",
    "\n",
    "# %%\n",
    "# Next steps\n",
    "print(\"\\nNext: Proceed to 03_model_training.ipynb for model development and optimization.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
